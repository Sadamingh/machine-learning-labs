{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding学习笔记4 - 应用\n",
    "\n",
    "Word Embedding反映了单词间的关联程度，经常在一起出现的词倾向在词向量空间里互相接近，所以向量间距离与词间的关联高度相关。\n",
    "\n",
    "## 1. 单词类比\n",
    "下面来看一个通过Word Embedding寻找相似词的例子。训练word embedding的计算量非常大，一般的机器学习都是使用事先训练好的模型，这里也使用[GloVe](https://nlp.stanford.edu/projects/glove/)50维的模型。模型可以在网站上下载，模型就是一个文本文件，每一行的开头是单词，接下来按有顺序列出向量值。\n",
    "\n",
    "### 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "word_to_vec_map = dict()\n",
    "f = open('glove.6B.50d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    word_to_vec_map[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.68224 , -0.31608 , -0.95201 ,  0.47108 ,  0.56571 ,  0.13151 ,\n",
       "        0.22457 ,  0.094995, -1.3237  , -0.51545 , -0.39337 ,  0.88488 ,\n",
       "        0.93826 ,  0.22931 ,  0.088624, -0.53908 ,  0.23396 ,  0.73245 ,\n",
       "       -0.019123, -0.26552 , -0.40433 , -1.5832  ,  1.1316  ,  0.4419  ,\n",
       "       -0.48218 ,  0.4828  ,  0.14938 ,  1.1245  ,  1.0159  , -0.50213 ,\n",
       "        0.83831 , -0.31303 ,  0.083242,  1.7161  ,  0.15024 ,  1.0324  ,\n",
       "       -1.5005  ,  0.62348 ,  0.54508 , -0.88484 ,  0.53279 , -0.085119,\n",
       "        0.02141 , -0.56629 ,  1.1463  ,  0.6464  ,  0.78318 , -0.067662,\n",
       "        0.22884 , -0.042453], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_vec_map['cucumber']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity\n",
    "\n",
    "计算公式如下\n",
    "\n",
    "$$\\text{CosineSimilarity(u, v)} = \\frac {u . v} {||u||_2 ||v||_2} = cos(\\theta) \\tag{1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(u, v):\n",
    "\n",
    "    dot = np.dot(u,v)\n",
    "    norm_u = np.linalg.norm(u)\n",
    "    norm_v = np.linalg.norm(v)\n",
    "    cosine_similarity = dot / (norm_u * norm_v) \n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算最佳单词匹配\n",
    "找到一个单词，使用其与word_c最接近于word_a与word_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_analogy(word_a, word_b, word_c, word_to_vec_map):\n",
    "    word_a, word_b, word_c = word_a.lower(), word_b.lower(), word_c.lower()\n",
    "    e_a, e_b, e_c =  word_to_vec_map[word_a],  word_to_vec_map[word_b],  word_to_vec_map[word_c]\n",
    "    \n",
    "    words = word_to_vec_map.keys()\n",
    "    max_cosine_sim = -100             \n",
    "    best_word = None                   \n",
    "\n",
    "    for w in words:        \n",
    "        # to avoid best_word being one of the input words, pass on them.\n",
    "        if w in [word_a, word_b, word_c] :\n",
    "            continue\n",
    "\n",
    "        cosine_sim =  cosine_similarity(e_b - e_a, word_to_vec_map[w] - e_c)\n",
    "        \n",
    "        if cosine_sim > max_cosine_sim:\n",
    "            max_cosine_sim = cosine_sim\n",
    "            best_word = w\n",
    "        \n",
    "    return best_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 示例\n",
    "\n",
    "给出italy, italian和china,它能找到Chinese，同样的heater和summer对应于cooler和winter。Word Embedding把自然语言映射到向量空间，保留了单词间的相关性，这使得Word Embedding能大幅提升机器学习的性能。我们也注意到word embedding并非一把万能钥匙，比如tree和tall，grass和6-feet就不是最好的匹配，所以在模型中还要辅之以其它手段。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "italy -> italian :: china -> chinese\n",
      "india -> delhi :: japan -> tokyo\n",
      "man -> woman :: boy -> girl\n",
      "small -> smaller :: large -> larger\n",
      "heater -> summer :: cooler -> winter\n",
      "tree -> tall :: grass -> 6-feet\n"
     ]
    }
   ],
   "source": [
    "triads_to_try = [('italy', 'italian', 'china'), ('india', 'delhi', 'japan'), \n",
    "                 ('man', 'woman', 'boy'), ('small', 'smaller', 'large'),\n",
    "                ('heater', 'summer', 'cooler'),\n",
    "                ('tree', 'tall', 'grass')]\n",
    "for triad in triads_to_try:\n",
    "    print ('{} -> {} :: {} -> {}'.format( *triad, complete_analogy(*triad,word_to_vec_map)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 文本分类\n",
    "\n",
    "Word Embedding还可以用于文本分类，一种常用的办法是把文本中所有的单词向量加和求平均，这样就可以得到一个文本向量，类似的利用这个向量我们可以给文本分类。我们来看下面这个例子\n",
    "\n",
    "### Corpus\n",
    "\n",
    "Corpus中都是一些简单的句子，根据含义打上标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "wpt = nltk.WordPunctTokenizer()\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "pd.options.display.max_colwidth = 200\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The sky is blue and beautiful.</td>\n",
       "      <td>weather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Love this blue and beautiful sky!</td>\n",
       "      <td>weather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The quick brown fox jumps over the lazy dog.</td>\n",
       "      <td>animals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A king's breakfast has sausages, ham, bacon, eggs, toast and beans</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I love green eggs, ham, sausages and bacon!</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The brown fox is quick and the blue dog is lazy!</td>\n",
       "      <td>animals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The sky is very blue and the sky is very beautiful today</td>\n",
       "      <td>weather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The dog is lazy but the brown fox is quick!</td>\n",
       "      <td>animals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>We will have chicken salad and meatball on the lunch menu</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             Document Category\n",
       "0                                      The sky is blue and beautiful.  weather\n",
       "1                                   Love this blue and beautiful sky!  weather\n",
       "2                        The quick brown fox jumps over the lazy dog.  animals\n",
       "3  A king's breakfast has sausages, ham, bacon, eggs, toast and beans     food\n",
       "4                         I love green eggs, ham, sausages and bacon!     food\n",
       "5                    The brown fox is quick and the blue dog is lazy!  animals\n",
       "6            The sky is very blue and the sky is very beautiful today  weather\n",
       "7                         The dog is lazy but the brown fox is quick!  animals\n",
       "8           We will have chicken salad and meatball on the lunch menu     food"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = ['The sky is blue and beautiful.',\n",
    "          'Love this blue and beautiful sky!',\n",
    "          'The quick brown fox jumps over the lazy dog.',\n",
    "          \"A king's breakfast has sausages, ham, bacon, eggs, toast and beans\",\n",
    "          'I love green eggs, ham, sausages and bacon!',\n",
    "          'The brown fox is quick and the blue dog is lazy!',\n",
    "          'The sky is very blue and the sky is very beautiful today',\n",
    "          'The dog is lazy but the brown fox is quick!', \n",
    "          'We will have chicken salad and meatball on the lunch menu'\n",
    "]\n",
    "labels = ['weather', 'weather', 'animals', 'food', 'food', 'animals', 'weather', 'animals', 'food']\n",
    "\n",
    "corpus = np.array(corpus)\n",
    "corpus_df = pd.DataFrame({'Document': corpus, \n",
    "                          'Category': labels})\n",
    "corpus_df = corpus_df[['Document', 'Category']]\n",
    "corpus_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文本预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_document(doc):\n",
    "    # lower case and remove special characters\\whitespaces\n",
    "    doc = re.sub(r'[^a-zA-Z\\s]', '', doc, re.I|re.A)\n",
    "    doc = doc.lower()\n",
    "    doc = doc.strip()\n",
    "    # tokenize document\n",
    "    tokens = wpt.tokenize(doc)\n",
    "    # filter stopwords out of document\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    # re-create document from filtered tokens\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 求向量平均"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_word_vectors(words, word_to_vec_map, num_features):\n",
    "    \n",
    "    words = normalize_document(words).split()\n",
    "\n",
    "    # Initialize the average word vector, should have the same shape as your word vectors.\n",
    "    avg = np.zeros((num_features,),dtype=\"float64\")\n",
    "    \n",
    "    # Step 2: average the word vectors. You can loop over the words in the list \"words\".\n",
    "    for w in words:\n",
    "        avg += word_to_vec_map[w]\n",
    "    avg = avg / len(words)\n",
    "    \n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def averaged_word_vectorizer(corpus,word_to_vec_map, num_features):\n",
    "    features = [average_word_vectors(tokenized_sentence, word_to_vec_map, num_features)\n",
    "                    for tokenized_sentence in corpus]\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.070063</td>\n",
       "      <td>0.948163</td>\n",
       "      <td>-0.435433</td>\n",
       "      <td>0.175210</td>\n",
       "      <td>0.608993</td>\n",
       "      <td>-0.240272</td>\n",
       "      <td>-0.888340</td>\n",
       "      <td>-0.617700</td>\n",
       "      <td>-0.141550</td>\n",
       "      <td>0.014403</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095337</td>\n",
       "      <td>0.094762</td>\n",
       "      <td>0.042676</td>\n",
       "      <td>-0.412580</td>\n",
       "      <td>0.105943</td>\n",
       "      <td>-0.032980</td>\n",
       "      <td>0.032116</td>\n",
       "      <td>-1.113610</td>\n",
       "      <td>0.127025</td>\n",
       "      <td>-0.273236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.087262</td>\n",
       "      <td>0.996148</td>\n",
       "      <td>-0.539605</td>\n",
       "      <td>0.058378</td>\n",
       "      <td>0.645580</td>\n",
       "      <td>0.026701</td>\n",
       "      <td>-0.745780</td>\n",
       "      <td>-0.461470</td>\n",
       "      <td>-0.193068</td>\n",
       "      <td>0.279077</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089193</td>\n",
       "      <td>0.022756</td>\n",
       "      <td>-0.014368</td>\n",
       "      <td>-0.349673</td>\n",
       "      <td>0.140128</td>\n",
       "      <td>0.027225</td>\n",
       "      <td>0.031818</td>\n",
       "      <td>-1.177982</td>\n",
       "      <td>0.023754</td>\n",
       "      <td>-0.132477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.155053</td>\n",
       "      <td>-0.181450</td>\n",
       "      <td>-0.129890</td>\n",
       "      <td>-0.173792</td>\n",
       "      <td>0.299837</td>\n",
       "      <td>0.366166</td>\n",
       "      <td>-0.671640</td>\n",
       "      <td>-0.184704</td>\n",
       "      <td>0.225717</td>\n",
       "      <td>-0.058557</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.148406</td>\n",
       "      <td>0.405689</td>\n",
       "      <td>-0.484404</td>\n",
       "      <td>0.180538</td>\n",
       "      <td>0.259395</td>\n",
       "      <td>-0.476827</td>\n",
       "      <td>0.343665</td>\n",
       "      <td>-0.333145</td>\n",
       "      <td>0.443393</td>\n",
       "      <td>0.738926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.130645</td>\n",
       "      <td>0.014894</td>\n",
       "      <td>-0.745699</td>\n",
       "      <td>-0.450485</td>\n",
       "      <td>0.603086</td>\n",
       "      <td>0.141869</td>\n",
       "      <td>-0.621366</td>\n",
       "      <td>0.115577</td>\n",
       "      <td>-0.468255</td>\n",
       "      <td>-0.074190</td>\n",
       "      <td>...</td>\n",
       "      <td>0.527570</td>\n",
       "      <td>0.309405</td>\n",
       "      <td>-0.364525</td>\n",
       "      <td>-0.066737</td>\n",
       "      <td>0.843510</td>\n",
       "      <td>0.984548</td>\n",
       "      <td>-0.337868</td>\n",
       "      <td>-0.060494</td>\n",
       "      <td>-0.193592</td>\n",
       "      <td>0.047151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.172892</td>\n",
       "      <td>0.164394</td>\n",
       "      <td>-0.705757</td>\n",
       "      <td>-0.629519</td>\n",
       "      <td>0.631528</td>\n",
       "      <td>0.654967</td>\n",
       "      <td>-0.536804</td>\n",
       "      <td>-0.155917</td>\n",
       "      <td>-0.348110</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.580172</td>\n",
       "      <td>0.112881</td>\n",
       "      <td>-0.165277</td>\n",
       "      <td>-0.193282</td>\n",
       "      <td>1.078478</td>\n",
       "      <td>0.766283</td>\n",
       "      <td>-0.234971</td>\n",
       "      <td>-0.359087</td>\n",
       "      <td>-0.065122</td>\n",
       "      <td>0.115561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.217797</td>\n",
       "      <td>-0.008480</td>\n",
       "      <td>-0.334692</td>\n",
       "      <td>-0.084680</td>\n",
       "      <td>0.350425</td>\n",
       "      <td>0.257451</td>\n",
       "      <td>-0.934252</td>\n",
       "      <td>-0.337239</td>\n",
       "      <td>0.078827</td>\n",
       "      <td>-0.187962</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049663</td>\n",
       "      <td>0.391125</td>\n",
       "      <td>-0.510334</td>\n",
       "      <td>0.087538</td>\n",
       "      <td>0.402928</td>\n",
       "      <td>-0.302605</td>\n",
       "      <td>0.087711</td>\n",
       "      <td>-0.479698</td>\n",
       "      <td>0.358139</td>\n",
       "      <td>0.699450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.025764</td>\n",
       "      <td>0.843176</td>\n",
       "      <td>-0.210532</td>\n",
       "      <td>0.244576</td>\n",
       "      <td>0.550792</td>\n",
       "      <td>-0.474389</td>\n",
       "      <td>-0.855704</td>\n",
       "      <td>-0.531754</td>\n",
       "      <td>-0.191738</td>\n",
       "      <td>-0.090750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078822</td>\n",
       "      <td>0.072205</td>\n",
       "      <td>0.043103</td>\n",
       "      <td>-0.309666</td>\n",
       "      <td>-0.014684</td>\n",
       "      <td>0.131104</td>\n",
       "      <td>-0.050228</td>\n",
       "      <td>-0.693502</td>\n",
       "      <td>0.078739</td>\n",
       "      <td>-0.242696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.093854</td>\n",
       "      <td>-0.149302</td>\n",
       "      <td>-0.298814</td>\n",
       "      <td>-0.148994</td>\n",
       "      <td>0.302126</td>\n",
       "      <td>0.314439</td>\n",
       "      <td>-0.879582</td>\n",
       "      <td>-0.207095</td>\n",
       "      <td>0.149908</td>\n",
       "      <td>-0.133194</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035248</td>\n",
       "      <td>0.481983</td>\n",
       "      <td>-0.597990</td>\n",
       "      <td>0.166470</td>\n",
       "      <td>0.359792</td>\n",
       "      <td>-0.301392</td>\n",
       "      <td>0.102778</td>\n",
       "      <td>-0.336318</td>\n",
       "      <td>0.421462</td>\n",
       "      <td>0.887272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.284182</td>\n",
       "      <td>-0.362885</td>\n",
       "      <td>-1.216550</td>\n",
       "      <td>-0.027102</td>\n",
       "      <td>0.984914</td>\n",
       "      <td>-0.114748</td>\n",
       "      <td>-0.319011</td>\n",
       "      <td>-0.253618</td>\n",
       "      <td>0.149884</td>\n",
       "      <td>-0.231138</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222712</td>\n",
       "      <td>0.567541</td>\n",
       "      <td>-0.391458</td>\n",
       "      <td>0.200307</td>\n",
       "      <td>0.784230</td>\n",
       "      <td>1.124014</td>\n",
       "      <td>0.215358</td>\n",
       "      <td>0.026194</td>\n",
       "      <td>0.482786</td>\n",
       "      <td>0.561606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -0.070063  0.948163 -0.435433  0.175210  0.608993 -0.240272 -0.888340   \n",
       "1 -0.087262  0.996148 -0.539605  0.058378  0.645580  0.026701 -0.745780   \n",
       "2 -0.155053 -0.181450 -0.129890 -0.173792  0.299837  0.366166 -0.671640   \n",
       "3  0.130645  0.014894 -0.745699 -0.450485  0.603086  0.141869 -0.621366   \n",
       "4  0.172892  0.164394 -0.705757 -0.629519  0.631528  0.654967 -0.536804   \n",
       "5 -0.217797 -0.008480 -0.334692 -0.084680  0.350425  0.257451 -0.934252   \n",
       "6 -0.025764  0.843176 -0.210532  0.244576  0.550792 -0.474389 -0.855704   \n",
       "7 -0.093854 -0.149302 -0.298814 -0.148994  0.302126  0.314439 -0.879582   \n",
       "8  0.284182 -0.362885 -1.216550 -0.027102  0.984914 -0.114748 -0.319011   \n",
       "\n",
       "         7         8         9     ...           40        41        42  \\\n",
       "0 -0.617700 -0.141550  0.014403    ...     0.095337  0.094762  0.042676   \n",
       "1 -0.461470 -0.193068  0.279077    ...     0.089193  0.022756 -0.014368   \n",
       "2 -0.184704  0.225717 -0.058557    ...    -0.148406  0.405689 -0.484404   \n",
       "3  0.115577 -0.468255 -0.074190    ...     0.527570  0.309405 -0.364525   \n",
       "4 -0.155917 -0.348110  0.000800    ...     0.580172  0.112881 -0.165277   \n",
       "5 -0.337239  0.078827 -0.187962    ...    -0.049663  0.391125 -0.510334   \n",
       "6 -0.531754 -0.191738 -0.090750    ...     0.078822  0.072205  0.043103   \n",
       "7 -0.207095  0.149908 -0.133194    ...    -0.035248  0.481983 -0.597990   \n",
       "8 -0.253618  0.149884 -0.231138    ...     0.222712  0.567541 -0.391458   \n",
       "\n",
       "         43        44        45        46        47        48        49  \n",
       "0 -0.412580  0.105943 -0.032980  0.032116 -1.113610  0.127025 -0.273236  \n",
       "1 -0.349673  0.140128  0.027225  0.031818 -1.177982  0.023754 -0.132477  \n",
       "2  0.180538  0.259395 -0.476827  0.343665 -0.333145  0.443393  0.738926  \n",
       "3 -0.066737  0.843510  0.984548 -0.337868 -0.060494 -0.193592  0.047151  \n",
       "4 -0.193282  1.078478  0.766283 -0.234971 -0.359087 -0.065122  0.115561  \n",
       "5  0.087538  0.402928 -0.302605  0.087711 -0.479698  0.358139  0.699450  \n",
       "6 -0.309666 -0.014684  0.131104 -0.050228 -0.693502  0.078739 -0.242696  \n",
       "7  0.166470  0.359792 -0.301392  0.102778 -0.336318  0.421462  0.887272  \n",
       "8  0.200307  0.784230  1.124014  0.215358  0.026194  0.482786  0.561606  \n",
       "\n",
       "[9 rows x 50 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_feature_array = averaged_word_vectorizer(corpus=corpus_df.Document, word_to_vec_map=word_to_vec_map,\n",
    "                                             num_features=50)\n",
    "pd.DataFrame(w2v_feature_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AP(Affinity Propagation)聚类算法\n",
    "\n",
    "AP算法的基本思想是将全部样本看做网络的节点，然后通过网络中各条边的消息传递计算出个样本的聚类中心。聚类过程中，共有两种消息在各节点间传递，分别是吸引度（responsibility）和归属度（availability）。AP算法通过迭代过程不断更新每一个点的吸引度和归属度，直到产生m个高质量的Exemplar（相当于质心），同时将其余的数据点分配到相应的聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Category</th>\n",
       "      <th>ClusterLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The sky is blue and beautiful.</td>\n",
       "      <td>weather</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Love this blue and beautiful sky!</td>\n",
       "      <td>weather</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The quick brown fox jumps over the lazy dog.</td>\n",
       "      <td>animals</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A king's breakfast has sausages, ham, bacon, eggs, toast and beans</td>\n",
       "      <td>food</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I love green eggs, ham, sausages and bacon!</td>\n",
       "      <td>food</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The brown fox is quick and the blue dog is lazy!</td>\n",
       "      <td>animals</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The sky is very blue and the sky is very beautiful today</td>\n",
       "      <td>weather</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The dog is lazy but the brown fox is quick!</td>\n",
       "      <td>animals</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>We will have chicken salad and meatball on the lunch menu</td>\n",
       "      <td>food</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             Document  \\\n",
       "0                                      The sky is blue and beautiful.   \n",
       "1                                   Love this blue and beautiful sky!   \n",
       "2                        The quick brown fox jumps over the lazy dog.   \n",
       "3  A king's breakfast has sausages, ham, bacon, eggs, toast and beans   \n",
       "4                         I love green eggs, ham, sausages and bacon!   \n",
       "5                    The brown fox is quick and the blue dog is lazy!   \n",
       "6            The sky is very blue and the sky is very beautiful today   \n",
       "7                         The dog is lazy but the brown fox is quick!   \n",
       "8           We will have chicken salad and meatball on the lunch menu   \n",
       "\n",
       "  Category  ClusterLabel  \n",
       "0  weather             0  \n",
       "1  weather             0  \n",
       "2  animals             2  \n",
       "3     food             1  \n",
       "4     food             1  \n",
       "5  animals             2  \n",
       "6  weather             0  \n",
       "7  animals             2  \n",
       "8     food             1  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import AffinityPropagation\n",
    "\n",
    "ap = AffinityPropagation()\n",
    "ap.fit(w2v_feature_array)\n",
    "cluster_labels = ap.labels_\n",
    "cluster_labels = pd.DataFrame(cluster_labels, columns=['ClusterLabel'])\n",
    "pd.concat([corpus_df, cluster_labels], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 两维PCA\n",
    "\n",
    "Principal Component Analysis(PCA)是最常用的线性降维方法，它的目标是通过某种线性投影，将高维的数据映射到低维的空间中表示，并期望在所投影的维度上数据的方差最大，以此使用较少的数据维度，同时保留住较多的原数据点的特性。\n",
    "\n",
    "我们把这些数据映射到两维空间方便绘图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2, random_state=0)\n",
    "pcs = pca.fit_transform(w2v_feature_array)\n",
    "labels = ap.labels_\n",
    "categories = list(corpus_df['Category'])\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    label = labels[i]\n",
    "    color = 'orange' if label == 0 else 'blue' if label == 1 else 'green'\n",
    "    annotation_label = categories[i]\n",
    "    x, y = pcs[i]\n",
    "    plt.scatter(x, y, c=color, edgecolors='k')\n",
    "    plt.annotate(annotation_label, xy=(x+1e-4, y+1e-3), xytext=(0, 0), textcoords='offset points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
